{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Poetic Text Generator Using RNN**"
      ],
      "metadata": {
        "id": "TOk81HvmpleY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing Dependencies"
      ],
      "metadata": {
        "id": "XpFdDVj7oIMH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "GRjAzag6-r-J"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Activation\n",
        "from tensorflow.keras.optimizers import RMSprop"
      ],
      "metadata": {
        "id": "vAtv_zRBl3QO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing shakespeare.txt file to get data from"
      ],
      "metadata": {
        "id": "D2G1SR3roLpa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filepath = tf.keras.utils.get_file('shakespeare.txt','https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')\n",
        "text = open(filepath, 'rb').read().decode(encoding='utf-8').lower()"
      ],
      "metadata": {
        "id": "1u0sknjXl5Ez",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6c209f2-230c-4f01-c8f9-c5682fcebbc2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
            "\u001b[1m1115394/1115394\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(text))"
      ],
      "metadata": {
        "id": "07VzmMHanmdp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c993ca77-dc11-4aa1-8759-428f2b4b3352"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1115394\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "dgSt81WvoRqs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "characters = sorted(set(text))\n",
        "\n",
        "char_to_index = dict((c, i) for i, c in enumerate(characters))\n",
        "index_to_char = dict((i, c) for i, c in enumerate(characters))"
      ],
      "metadata": {
        "id": "05T2z7pvl_sn"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SEQ_LENGTH is the max length of the sequence which will be parsed at once"
      ],
      "metadata": {
        "id": "Jq0l2CiSoUHB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SEQ_LENGTH = 40\n",
        "STEP_SIZE = 3\n",
        "\n",
        "sentences = []\n",
        "next_char = []"
      ],
      "metadata": {
        "id": "gZq9uc8FnZ96"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0, len(text) - SEQ_LENGTH, STEP_SIZE):\n",
        "    sentences.append(text[i: i + SEQ_LENGTH])\n",
        "    next_char.append(text[i + SEQ_LENGTH])"
      ],
      "metadata": {
        "id": "xYSHSY98oC_8"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assigning one dimension to all the sentences we have, one dimension to all the individual positions in the sentences and one dimension for all the possible characters that we can have. Now whenever a particular character occurs in any particular position in any particular sentence, we set that to one and all the other values will remain zero."
      ],
      "metadata": {
        "id": "SHbDyknao21N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.zeros((len(sentences), SEQ_LENGTH, len(characters)), dtype = bool)\n",
        "y = np.zeros((len(sentences), len(characters)), dtype = bool)\n",
        "\n",
        "for i, satz in enumerate(sentences):\n",
        "    for t, char in enumerate(satz):\n",
        "        x[i, t, char_to_index[char]] = 1\n",
        "    y[i, char_to_index[next_char[i]]] = 1"
      ],
      "metadata": {
        "id": "BUbXTiiuoHbL"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Building the neural network**"
      ],
      "metadata": {
        "id": "jVOKi6RRp6Jb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(SEQ_LENGTH, len(characters))))\n",
        "model.add(Dense(len(characters)))\n",
        "model.add(Activation('softmax'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kwo_UrIjpon3",
        "outputId": "cb13cee6-0aaf-48f8-a3fa-d7c1431e4cb6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(learning_rate=0.01))\n",
        "model.fit(x, y, batch_size=256, epochs=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jMcMZsshqMAx",
        "outputId": "6b57ca14-d613-4291-f52a-d4f5df6ad8c4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "\u001b[1m1453/1453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - loss: 2.2320\n",
            "Epoch 2/4\n",
            "\u001b[1m1453/1453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - loss: 1.6146\n",
            "Epoch 3/4\n",
            "\u001b[1m1453/1453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - loss: 1.5138\n",
            "Epoch 4/4\n",
            "\u001b[1m1453/1453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - loss: 1.4624\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x794f2a8b3850>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('Poetic_Text_Generator.h5' )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vuMMOa7OrYL6",
        "outputId": "47a7831f-b3b6-4c8a-8823-47e5488839b1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Helper Function"
      ],
      "metadata": {
        "id": "DCuBMAILqN4Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sample(preds, temperature=1.0):\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)"
      ],
      "metadata": {
        "id": "QxPuCOAAqQNb"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This helper function called sample is copied from the [official Keras tutorial](https://keras.io/examples/generative/lstm_character_level_text_generation/)."
      ],
      "metadata": {
        "id": "pyh__tcdsFha"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(length, temp):\n",
        "    start_index = random.randint(0, len(text) - SEQ_LENGTH - 1)\n",
        "    generated = ''\n",
        "    sentence = text[start_index: start_index + SEQ_LENGTH]\n",
        "    generated += sentence\n",
        "    for i in range(length):\n",
        "        x_pred = np.zeros((1, SEQ_LENGTH, len(characters)))\n",
        "        for t, char in enumerate(sentence):\n",
        "            x_pred[0, t, char_to_index[char]] = 1\n",
        "\n",
        "        predi = model.predict(x_pred, verbose=0)[0]\n",
        "        next_index = sample(predi,temp)\n",
        "        next_character = index_to_char[next_index]\n",
        "\n",
        "        generated += next_character\n",
        "        sentence = sentence[1:] + next_character\n",
        "    return generated"
      ],
      "metadata": {
        "id": "BkY07g2KrkH0"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_text(300, 0.1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1HYAvpbKueKu",
        "outputId": "379c37f3-832d-42cf-c79e-dca2c6a8c177"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ed,\n",
            "but what my power might else exact, and the sense and the sense and the dear\n",
            "the most consent and the sense the sense of the consent\n",
            "and the sense the consent and the sense and the sense of the consent\n",
            "and the sense of the dear and the sense and the sense of the consent\n",
            "to the send the send the sense the love,\n",
            "and the matter of the se\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_text(300, 0.2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "203736oHtHIa",
        "outputId": "cb75011e-3947-4796-c7a4-f5a258d9697e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " salisbury; the rest march on with me.\n",
            "\n",
            "clown:\n",
            "i have speak and the sense of the sense and the consent\n",
            "is the sense the matter soul the most\n",
            "she hath stand a the love and the death to the dear\n",
            "and send the greatest the surpering and the sense,\n",
            "and the son and the consent to the dead.\n",
            "\n",
            "gloucester:\n",
            "i am stranger to the grosse and the most\n",
            "s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_text(300, 0.3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9_y-zHKIuTkM",
        "outputId": "db7244e7-91e5-40e1-b185-c54b288054d8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "no: the princess hearing of her mother's heads\n",
            "the consent and the matter to the sires,\n",
            "and the matter the books of your son and fear,\n",
            "i will see you shall be the greatest consent.\n",
            "\n",
            "autolycus:\n",
            "the bear the good fair morning mercy heaven,\n",
            "the consent and makes and place and be no more.\n",
            "\n",
            "gloucester:\n",
            "my lord, and the great men are and the c\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_text(300, 0.4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0snfPnwguW-7",
        "outputId": "2494dd04-b60e-4835-c1de-db312b4b35d3"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ngs, the fool was drown'd.\n",
            "\n",
            "king henry vi:\n",
            "are thou will live of the warrant and matcher consentes.\n",
            "\n",
            "brutus:\n",
            "i cannot the speak to the force entertains.\n",
            "\n",
            "prospero:\n",
            "and steads and make of the dead to dear to be\n",
            "where is in my consente with plains and the canst\n",
            "and a grave and the fall of a man, and the comes,\n",
            "what is the good matches to go\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_text(300, 0.5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "St8uBYYZuX8m",
        "outputId": "543b533c-c829-4fec-adae-bb45f3051e4e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "and this brave fellow too, we are the grace,\n",
            "and the sent ententain and tranch in our cannate\n",
            "for the heavens, if the full and the tencher's consent\n",
            "as i maint the said the rest the disencentious provest many.\n",
            "\n",
            "provost:\n",
            "go his my father with sums; and these name?\n",
            "\n",
            "queen elizabeth:\n",
            "what love a gine and for preciess to makes it.\n",
            "\n",
            "duke vinc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_text(300, 0.6))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gjkjVa0nuYiX",
        "outputId": "c3142a15-c7fb-46dd-e33b-8749c6bdc6b1"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " to attain it.\n",
            "\n",
            "henry bolingbroke:\n",
            "evermat far only be so't bear consence,\n",
            "and hot the live, here claught in a clarence.\n",
            "\n",
            "romeo:\n",
            "what's may make with themself, and yet consent;\n",
            "and with him love i will for comes in my from\n",
            "here she were and makest the sen.\n",
            "\n",
            "king henry vi:\n",
            "but, by this well and to leave your voice, i feal.\n",
            "\n",
            "cominius:\n",
            "the o\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_text(300, 0.7))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ToiiXELtuZHV",
        "outputId": "007dd4e5-ff4e-4fd7-a158-14ad914198b1"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n the sand; why, there you quickly sink:\n",
            "i brancent annop unstruck and shame's better\n",
            "is thy letter armsrort, as a cates'd take in the matter.\n",
            "\n",
            "binrtent:\n",
            "it our heavon revenge to shall in the countaine of suchnough,\n",
            "that in fear where and a the must is in the appose\n",
            "unchued bloody cannot put freen's cheeking is\n",
            "is a so-love for contraring\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_text(300, 0.8))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzRuDkfAuZ6o",
        "outputId": "13d81bb3-01fd-4fbd-a0d5-67b4c7a45e80"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "me to reprehend my ignorance.\n",
            "\n",
            "buckingham:\n",
            "clarence: all untine to have warrant of the creasure\n",
            "to the dide all a borning' to death.\n",
            "\n",
            "lord glovio:\n",
            "romeo, he slain of in which hearen wook against.\n",
            "deselves untowning. what from and in this the liberance.\n",
            "as while royal clarence sheet watch and come.\n",
            "so consentions to be adonce in as incenou\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_text(300, 0.9))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xYmuzgFOubxx",
        "outputId": "9347d4bf-8f6e-489f-fda9-24612713799f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hivalry,\n",
            "as is the sepulchre in stubborns, because a worn,\n",
            "the lords, living, speak, enemb the dealts, point anbellower:\n",
            "he never dead the sproon git, and stien!\n",
            "\n",
            "menenius: if thou knee; cannot still.\n",
            "\n",
            "roman, incenoughhnerss lough,\n",
            "and yet makest away; and sity.'\n",
            "\n",
            "romeo:\n",
            "and the books; and sharture armost knows.\n",
            "\n",
            "buckingham:\n",
            "i mignt let b\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_text(300, 1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G14MOM1-ucwk",
        "outputId": "1888f102-fd1a-4c0d-ec3f-459a9d8617d6"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "th the consent of supreme jove, inform\n",
            "to bloody lawn like your deors, your meif he on late to follower\n",
            "much coverest is mercuty will poly. whats ears\n",
            "a being ware, i amturnne ake abroase;\n",
            "what over his take is are can what, tyloners:\n",
            "when i thereised enemies the seemeness to queen.\n",
            "he was eagh'stress epting, be sterns is bour netty,\n",
            "she \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_text(300, 0.01))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmD__H3puhh0",
        "outputId": "46bd1248-133a-4bf2-decc-743a9122313a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--what will you adventure\n",
            "to save this she shall be so stranger to the consent\n",
            "and the send the consent of the consent and the sense of the consent\n",
            "and the send the consent of the consent and the sense and the love,\n",
            "and the send the consent of the consent and the sense and the love,\n",
            "and the send the consent and the sense and the sense an\n"
          ]
        }
      ]
    }
  ]
}